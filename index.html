<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction - Roy El-Helou, Matthew K.X.J. Pan">
  <meta name="description" content="This study explores how human perceptions of non-anthropomorphic robotic manipulators can be shaped by arousal and attention. We present an integrated behaviour system that combines a gaze-like attention engine with an arousal-modulated motion layer.">
  <meta name="keywords" content="human-robot interaction, non-anthropomorphic robots, robotic manipulators, arousal, attention, social robotics, HRI, expressive behavior, robotic gaze">
  <meta name="author" content="Roy El-Helou, Matthew K.X.J. Pan">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Ingenuity Labs Research Institute, Queen's University">
  <meta property="og:title" content="The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction">
  <meta property="og:description" content="This study explores how human perceptions of non-anthropomorphic robotic manipulators can be shaped by arousal and attention. We present an integrated behaviour system that combines a gaze-like attention engine with an arousal-modulated motion layer.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://roy-elhelou.github.io/el2025social">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Roy El-Helou">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Human-Robot Interaction">
  <meta property="article:tag" content="Non-Anthropomorphic Robots">


  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction">
  <meta name="citation_author" content="El-Helou, Roy">
  <meta name="citation_author" content="Pan, Matthew K.X.J.">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction - Roy El-Helou, Matthew K.X.J. Pan | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/robot-holding-heart_icon-icons.com_55277.ico">
  <link rel="apple-touch-icon" href="static/images/robot-holding-heart_icon-icons.com_55277.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction",
    "description": "This study explores how human perceptions of non-anthropomorphic robotic manipulators can be shaped by arousal and attention. We present an integrated behaviour system that combines a gaze-like attention engine with an arousal-modulated motion layer.",
    "author": [
      {
        "@type": "Person",
        "name": "Roy El-Helou",
        "email": "19reh2@queensu.ca",
        "affiliation": {
          "@type": "Organization",
          "name": "Ingenuity Labs Research Institute, Queen's University"
        }
      },
      {
        "@type": "Person",
        "name": "Matthew K.X.J. Pan",
        "email": "matthew.pan@queensu.ca",
        "affiliation": {
          "@type": "Organization",
          "name": "Ingenuity Labs Research Institute, Queen's University"
        }
      }
    ],
    "datePublished": "2025-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "Human-Robot Interaction"
    },
    "url": "https://roy-elhelou.github.io/el2025social",
    "image": "https://roy-elhelou.github.io/el2025social/static/images/social_preview.png",
    "keywords": ["human-robot interaction", "non-anthropomorphic robots", "robotic manipulators", "arousal", "attention", "social robotics", "HRI", "expressive behavior"],
    "abstract": "This study explores how human perceptions of a non-anthropomorphic robotic manipulator can be shaped by two key dimensions of behaviour: arousal, defined as the robot's movement energy and expressiveness, and attention, defined as the robot's capacity to selectively orient toward and engage with a user. We present an integrated behaviour system that applies and extends existing movement-centric design principles to non-anthropomorphic robots. Our system combines a gaze-like attention engine with an arousal-modulated motion layer to explore how expressive and interactive behaviours influence social perception in robotic manipulators. In a user study, we find that robots exhibiting high attention—actively directing their focus toward users—are perceived as warmer and more competent, intentional, and lifelike. In contrast, high arousal—characterized by fast, expansive, and energetic motions—increases perceptions of discomfort and disturbance. Importantly, a combination of focused attention and moderate arousal yields the highest ratings of trust and sociability, while excessive arousal diminishes social engagement.",
    "citation": "@article{elhelou2025social, title={The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction}, author={El-Helou, Roy and Pan, Matthew K.X.J.}, year={2025}, url={https://roy-elhelou.github.io/el2025social}}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://roy-elhelou.github.io/el2025social"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Human-Robot Interaction"
      },
      {
        "@type": "Thing", 
        "name": "Non-Anthropomorphic Robots"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Ingenuity Labs Research Institute, Queen's University",
    "url": "https://www.ingenuitylabs.ca",
    "logo": "https://roy-elhelou.github.io/el2025social/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/IngenuityLabs",
      "https://github.com/roy-elhelou"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="mailto:19reh2@queensu.ca" target="_blank">Roy El-Helou</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="mailto:matthew.pan@queensu.ca" target="_blank">Matthew K.X.J. Pan</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Ingenuity Labs Research Institute<br>Department of Electrical and Computer Engineering<br>Queen's University, Kingston, Canada</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2504.01260" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2504.01260" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- System Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/System_Images_2.jpg" alt="Photos showing varying robot poses as a result of varying the arousal level of the proposed architecture controlling the emotional and social behaviours of a Universal Robots UR5e manipulator." style="width: 100%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered" style="margin-top: 2rem;">
        Can robots use behavioural cues to project emotional and social presence, even without anthropomorphic features?
      </h2>
    </div>
  </div>
</section>
<!-- End System Image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This study explores how human perceptions of a non-anthropomorphic robotic manipulator can be shaped by two key dimensions of behaviour: arousal, defined as the robot's movement energy and expressiveness, and attention, defined as the robot's capacity to selectively orient toward and engage with a user. We present an integrated behaviour system that applies and extends existing movement-centric design principles to non-anthropomorphic robots. Our system combines a gaze-like attention engine with an arousal-modulated motion layer to explore how expressive and interactive behaviours influence social perception in robotic manipulators. In a user study, we find that robots exhibiting high attention—actively directing their focus toward users—are perceived as warmer and more competent, intentional, and lifelike. In contrast, high arousal—characterized by fast, expansive, and energetic motions—increases perceptions of discomfort and disturbance. Importantly, a combination of focused attention and moderate arousal yields the highest ratings of trust and sociability, while excessive arousal diminishes social engagement. These findings offer design insights for endowing non-humanoid robots with expressive, intuitive behaviours that support more natural human-robot interaction.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- System Design -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">System Design</h2>
        <div class="content has-text-justified">
          <p>
            Our behaviour generation system integrates attention and arousal mechanisms to support expressive and socially responsive interaction in robotic manipulators. The system consists of two main components:
          </p>
          
          <!-- Figure 2: System architecture diagram -->
          <div class="has-text-centered" style="margin: 2rem 0;">
            <img src="static/images/System-Architecture.jpg" alt="System architecture diagram for our proposed interactive and expressive robot behaviour system" style="max-width: 80%; height: auto; display: block; margin: 0 auto;">
            <p class="is-size-6" style="margin-top: 0.5rem; font-style: italic;">
              System architecture diagram for our proposed interactive and expressive robot behaviour system.
            </p>
          </div>
          
          <h3 class="title is-4" style="margin-top: 1.5rem;">Attention Engine</h3>
          <p>
            The attention engine directs the robot's attention to salient features in its visual environment—specifically, users and individuals within range of an RGB-D sensor (Intel RealSense D435 Depth Camera). It computes an attention score for each detected individual, determining saliency and guiding the robot's gaze to enable dynamic, responsive interactions.
          </p>
          <p>
            Each attention score is a weighted combination of positional cues, movement dynamics, and a habituation factor that prevents prolonged fixation on a single target. The score Φ is defined as:
          </p>
          <p style="text-align: center; font-family: monospace; margin: 1rem 0;">
            Φ = w<sub>p</sub>P + w<sub>v</sub>V + Θ(t)
          </p>
          <p>
            where P combines proximity and hand position factors, V captures torso and hand motion, and Θ(t) is a habituation factor that dynamically adjusts based on gaze history to maintain naturalistic attention shifts.
          </p>

          <h3 class="title is-4" style="margin-top: 1.5rem;">Robotic Gaze Algorithm</h3>
          <p>
            The gaze algorithm maps 3D target positions to joint-space postures, enabling the robot to orient toward salient individuals. Arousal modulates posture and motion dynamics: low arousal produces subdued, minimal motion, while high arousal increases speed, amplitude, and reach. A sinusoidal oscillation is applied to joint angles to simulate breathing, with oscillation intensity scaling with arousal to enhance realism and lifelikeness.
          </p>

          <h3 class="title is-4" style="margin-top: 1.5rem;">Attentional Drift Module</h3>
          <p>
            To avoid mechanical stiffness from continuous fixation, we introduce an Attentional Drift Module that injects naturalistic variability into the robot's gaze behaviour. The module generates transient virtual targets within the robot's workspace probabilistically, with likelihood increasing alongside arousal level, creating momentary attentional shifts without disrupting motion continuity.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End System Design -->




<!-- Key Findings -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Findings</h2>
        <div class="content has-text-justified">
          <p>
            We conducted a user study with 36 participants (18 males, 18 females, ages 18-25) examining how variations in arousal and attention influence human perceptions of a non-anthropomorphic robot. The study employed a 2 × 2 factorial design, crossing two levels of arousal (low and high) with two levels of attention (low and high).
          </p>

          <h3 class="title is-4" style="margin-top: 1.5rem;">Effects of Attention</h3>
          <p>
            High attention significantly enhanced perceptions across multiple dimensions:
          </p>
          <ul>
            <li><strong>Warmth:</strong> Higher in high attention (M = 3.77) vs. low attention (M = 3.01), p < .001</li>
            <li><strong>Competence:</strong> Higher in high attention (M = 5.11) vs. low attention (M = 3.06), p < .001</li>
            <li><strong>Animacy:</strong> Higher in high attention (M = 4.10) vs. low attention (M = 3.44), p < .001</li>
            <li><strong>Intentionality:</strong> Higher in high attention (M = 4.95) vs. low attention (M = 3.53), p < .001</li>
            <li><strong>Sociability:</strong> Significantly improved with high attention, F(1, 35) = 7.22, p < .01</li>
          </ul>

          <h3 class="title is-4" style="margin-top: 1.5rem;">Effects of Arousal</h3>
          <p>
            High arousal had mixed effects:
          </p>
          <ul>
            <li><strong>Discomfort:</strong> Increased in high arousal (M = 3.87) vs. low arousal (M = 3.34), p < .01</li>
            <li><strong>Disturbance:</strong> Increased in high arousal, F(1, 35) = 7.58, p < .01</li>
            <li><strong>Sociability:</strong> Decreased in high arousal, F(1, 35) = 4.75, p < .05</li>
          </ul>

          <h3 class="title is-4" style="margin-top: 1.5rem;">Interaction Effects</h3>
          <p>
            The combination of high attention and low arousal yielded the most positive social outcomes:
          </p>
          
          <!-- Figure 3: Interaction effects visualization -->
          <div class="has-text-centered" style="margin: 2rem 0;">
            <img src="static/images/disco_interaction.png" alt="Interaction effect of arousal and attention on discomfort and sociability ratings" style="max-width: 100%; height: auto; display: block; margin: 0 auto;">
            <p class="is-size-6" style="margin-top: 0.5rem; font-style: italic;">
              Interaction effect of arousal and attention on discomfort and sociability ratings.
            </p>
          </div>
          
          <ul>
            <li>In high attention conditions, discomfort was significantly higher in high arousal (M = 3.71) than low arousal (M = 2.79), p < .01</li>
            <li>In high attention conditions, sociability was significantly lower in high arousal (M = 3.31) than low arousal (M = 4.17), p < .01</li>
            <li>Low arousal conditions resulted in longer interaction durations (M = 71.96s) than high arousal conditions (M = 62.21s), F = 4.66, p < .05</li>
          </ul>

          <p style="margin-top: 1.5rem;">
            <strong>Key Insight:</strong> The most socially successful behaviours emerged when attention was high and arousal remained low. Users prefer systems that are attentive without being overstimulating, reflecting broader human norms around affect regulation where calm focus is associated with trustworthiness and emotional control.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Key Findings -->


<!-- Contributions -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Contributions</h2>
        <div class="content has-text-justified">
          <p>
            This work presents a unified framework for endowing non-anthropomorphic robots with expressive, intuitive behaviours. Our contributions include:
          </p>
          <ul>
            <li><strong>Expressive Control System:</strong> We design an integrated system that combines arousal-based motion modulation with a real-time attention engine in a robotic manipulator, with natural motion continuity in mind.</li>
            <li><strong>Empirical Evaluation:</strong> We conduct a factorial user study that evaluates how attention and arousal jointly shape perceptions of discomfort and sociability in non-anthropomorphic robots.</li>
            <li><strong>Design Insights:</strong> We provide empirical insights into the social dynamics of expressive motion in non-humanoid robots, supporting their use in socially embedded contexts.</li>
          </ul>
          <p style="margin-top: 1rem;">
            These findings offer concrete guidance for the design of socially intuitive robotic systems, particularly in non-humanoid forms, demonstrating that even robots without human-like features can convey character-like behaviour when designed with appropriate expressive strategies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Contributions -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{elhelou2025social,
  title={The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction},
  author={El-Helou, Roy and Pan, Matthew K.X.J.},
  journal={Human-Robot Interaction},
  year={2025},
  url={https://roy-elhelou.github.io/el2025social}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
